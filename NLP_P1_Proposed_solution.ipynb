{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_P1_Proposed solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxw8if5pvkfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_train = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q9W77zzWjUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_test = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClmeOGVxzefT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a dataframe of columns Event 1 and 2 from the csv file\n",
        "import pandas as pd\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded_train['P1_training_set.csv']))\n",
        "df = pd.DataFrame(data, columns= ['Event 1','Event 2','Label'])\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgmWp7zyXOtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "data_y = pd.read_csv(io.BytesIO(uploaded_test['P1_testing_set.csv']))\n",
        "df_y = pd.DataFrame(data_y, columns= ['Event 1','Event 2','Label'])\n",
        "df_y.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVpW_yfC0Sw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "import warnings \n",
        "\n",
        "warnings.filterwarnings(action = 'ignore') \n",
        "\n",
        "import gensim \n",
        "from gensim.models import Word2Vec "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4l6nvsW1VQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ontDAVp0sFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Storing the listsof both the events in two separate lists\n",
        "event1 = []\n",
        "event2 = []\n",
        "label = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  event1.append(row['Event 1'])\n",
        "  event2.append(row['Event 2'])\n",
        "  label.append(row['Label'])\n",
        "\n",
        "#print(event1[0])\n",
        "#print(event2[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwuTNQj3Y1Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "event1_y = []\n",
        "event2_y = []\n",
        "label_y = []\n",
        "\n",
        "for index, row in df_y.iterrows():\n",
        "  event1_y.append(row['Event 1'])\n",
        "  event2_y.append(row['Event 2'])\n",
        "  label_y.append(row['Label'])\n",
        "\n",
        "#print(event1_y[0])\n",
        "#print(event2_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t47xnyd7dUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yv_RvSo9Fky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from nltk.corpus import stopwords \n",
        "stop_words=stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fi0yk4a9Pu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "#print(stop_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QpuMrYQapA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#proposed solution\n",
        "\n",
        "event1tokens = []\n",
        "for i in event1:\n",
        "    temp = word_tokenize(i)\n",
        "  \n",
        "    event1tokens.append(temp)\n",
        "#print(event1tokens[0])\n",
        "\n",
        "event2tokens = []\n",
        "for i in event2:\n",
        "    temp = word_tokenize(i)\n",
        "  \n",
        "    event2tokens.append(temp)\n",
        "#print(event2tokens[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_KMHgWXgFdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#proposed solution\n",
        "\n",
        "event1tokens_y = []\n",
        "for i in event1_y:\n",
        "    temp = word_tokenize(i)\n",
        "  \n",
        "    event1tokens_y.append(temp)\n",
        "#print(event1tokens_y[0])\n",
        "\n",
        "event2tokens_y = []\n",
        "for i in event2_y:\n",
        "    temp = word_tokenize(i)\n",
        "  \n",
        "    event2tokens_y.append(temp)\n",
        "#print(event2tokens_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFCUG5vicEZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iSVFuEBbWhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "event1tokens_cleaned=[]\n",
        "for i in event1tokens:\n",
        "  temp=[]\n",
        "  for token, tag in pos_tag(i):\n",
        "        if tag.startswith(\"NN\"):\n",
        "            pos = 'n'\n",
        "        elif tag.startswith('VB'):\n",
        "            pos = 'v'\n",
        "        else:\n",
        "            pos = 'a'\n",
        "\n",
        "        token = lemmatizer.lemmatize(token, pos).lower()\n",
        "\n",
        "        if token not in string.punctuation and token not in stop_words:\n",
        "            temp.append(token)\n",
        "  event1tokens_cleaned.append(temp)\n",
        "#print(event1tokens_cleaned[0])\n",
        "\n",
        "event2tokens_cleaned=[]\n",
        "for i in event2tokens:\n",
        "  temp=[]\n",
        "  for token, tag in pos_tag(i):\n",
        "        if tag.startswith(\"NN\"):\n",
        "            pos = 'n'\n",
        "        elif tag.startswith('VB'):\n",
        "            pos = 'v'\n",
        "        else:\n",
        "            pos = 'a'\n",
        "\n",
        "        token = lemmatizer.lemmatize(token, pos).lower()\n",
        "\n",
        "        if token not in string.punctuation and token not in stop_words:\n",
        "            temp.append(token)\n",
        "  event2tokens_cleaned.append(temp)\n",
        "#print(event2tokens_cleaned[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDGYNSVYgulx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "event1tokens_cleaned_y=[]\n",
        "for i in event1tokens_y:\n",
        "  temp=[]\n",
        "  for token, tag in pos_tag(i):\n",
        "        if tag.startswith(\"NN\"):\n",
        "            pos = 'n'\n",
        "        elif tag.startswith('VB'):\n",
        "            pos = 'v'\n",
        "        else:\n",
        "            pos = 'a'\n",
        "\n",
        "        token = lemmatizer.lemmatize(token, pos).lower()\n",
        "\n",
        "        if token not in string.punctuation and token not in stop_words:\n",
        "            temp.append(token)\n",
        "  event1tokens_cleaned_y.append(temp)\n",
        "#print(event1tokens_cleaned_y[0])\n",
        "\n",
        "event2tokens_cleaned_y=[]\n",
        "for i in event2tokens_y:\n",
        "  temp=[]\n",
        "  for token, tag in pos_tag(i):\n",
        "        if tag.startswith(\"NN\"):\n",
        "            pos = 'n'\n",
        "        elif tag.startswith('VB'):\n",
        "            pos = 'v'\n",
        "        else:\n",
        "            pos = 'a'\n",
        "\n",
        "        token = lemmatizer.lemmatize(token, pos).lower()\n",
        "\n",
        "        if token not in string.punctuation and token not in stop_words:\n",
        "            temp.append(token)\n",
        "  event2tokens_cleaned_y.append(temp)\n",
        "#print(event2tokens_cleaned_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY2Tp8t0ewEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating vectors for both the event tokens skip-gram model\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "word2vecEvent1 = Word2Vec(event1tokens_cleaned, min_count=1, sg=1)\n",
        "word2vecEvent2 = Word2Vec(event2tokens_cleaned, min_count=1, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4J2OuC2f6i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vecEvent1_y = Word2Vec(event1tokens_cleaned_y, min_count=1, sg=1)\n",
        "word2vecEvent2_y = Word2Vec(event2tokens_cleaned_y, min_count=1, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PwknE7_UItF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##calculating the average vector for every event sentence\n",
        "avgWordVecE1 = []\n",
        "for i in event1tokens_cleaned:\n",
        "  temp = [0]*100\n",
        "  n=len(i)\n",
        "  for j in i:\n",
        "    temp = temp+word2vecEvent1.wv[j]\n",
        "  temp=temp/n\n",
        "  avgWordVecE1.append(temp)\n",
        "#print(avgWordVecE1[0])\n",
        "\n",
        "avgWordVecE2 = []\n",
        "for i in event2tokens_cleaned:\n",
        "  temp = [0]*100\n",
        "  n=len(i)\n",
        "  for j in i:\n",
        "    temp = temp+word2vecEvent2.wv[j]\n",
        "  temp=temp/n\n",
        "  avgWordVecE2.append(temp)\n",
        "#print(avgWordVecE2[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZP-UZIYZLqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avgWordVecE1_y = []\n",
        "for i in event1tokens_cleaned_y:\n",
        "  temp = [0]*100\n",
        "  n=len(i)\n",
        "  for j in i:\n",
        "    temp = temp+word2vecEvent1_y.wv[j]\n",
        "  temp=temp/n\n",
        "  avgWordVecE1_y.append(temp)\n",
        "#print(avgWordVecE1_y[0])\n",
        "\n",
        "avgWordVecE2_y = []\n",
        "for i in event2tokens_cleaned_y:\n",
        "  temp = [0]*100\n",
        "  n=len(i)\n",
        "  for j in i:\n",
        "    temp = temp+word2vecEvent2_y.wv[j]\n",
        "  temp=temp/n\n",
        "  avgWordVecE2_y.append(temp)\n",
        "#print(avgWordVecE2_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cUPmDs7N4sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenating both the events\n",
        "event1and2 = []\n",
        "#n=len(avgWordVecE1)\n",
        "for i in range(len(avgWordVecE1)):\n",
        "  temp=[y for x in [avgWordVecE1[i], avgWordVecE2[i]] for y in x]\n",
        "  event1and2.append(temp)\n",
        "#print(len(event1and2[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGW1cOJyzMG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "numpy.save('trainingData_vectors', event1and2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Nt5h5FZbdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenating both the events\n",
        "event1and2_y = []\n",
        "#n=len(avgWordVecE1)\n",
        "for i in range(len(avgWordVecE1_y)):\n",
        "  temp=[y for x in [avgWordVecE1_y[i], avgWordVecE2_y[i]] for y in x]\n",
        "  event1and2_y.append(temp)\n",
        "#print(len(event1and2_y[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKdNQZnyziMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy.save('testingData_vectors', event1and2_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gKeTapASAJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training the classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(event1and2, label) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWlSs-MNdD7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(event1and2_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGQT2JupdYI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(label_y,y_pred))\n",
        "print(classification_report(label_y,y_pred))\n",
        "print(accuracy_score(label_y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}